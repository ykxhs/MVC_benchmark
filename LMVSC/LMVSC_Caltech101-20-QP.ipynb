{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large-scale Multi-view Subspace Clustering in Linear Time (Caltech101-20 Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "1. Main Paper: https://arxiv.org/pdf/1911.09290.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy import linalg\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from cvxpy.atoms.elementwise.power import power\n",
    "import cvxpy as cp\n",
    "from qpsolvers import solve_qp\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = np.load('cal20_gabor.npy')\n",
    "d2 = np.load('cal20_wave_moment.npy')\n",
    "d3 = np.load('cal20_centrist.npy')\n",
    "d4 = np.load('cal20_gist.npy')\n",
    "d5 = np.load('cal20_lbp.npy')\n",
    "d6 = np.load('cal20_hog.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1 = (d1 - d1.min(axis=0))/(d1.max(axis=0) - d1.min(axis=0))\n",
    "# d2 = (d2 - d2.min(axis=0))/(d2.max(axis=0) - d2.min(axis=0))\n",
    "# d3 = (d3 - d3.min(axis=0))/(d3.max(axis=0) - d3.min(axis=0))\n",
    "# d4 = (d4 - d4.min(axis=0))/(d4.max(axis=0) - d4.min(axis=0))\n",
    "# d5 = (d5 - d5.min(axis=0))/(d5.max(axis=0) - d5.min(axis=0))\n",
    "# d6 = (d6 - d6.min(axis=0))/(d6.max(axis=0) - d6.min(axis=0))\n",
    "d1 = (d1 - d1.min())/(d1.max() - d1.min())\n",
    "d2 = (d2 - d2.min())/(d2.max() - d2.min())\n",
    "d3 = (d3 - d3.min())/(d3.max() - d3.min())\n",
    "d4 = (d4 - d4.min())/(d4.max() - d4.min())\n",
    "d5 = (d5 - d5.min())/(d5.max() - d5.min())\n",
    "d6 = (d6 - d6.min())/(d6.max() - d6.min())\n",
    "# d1 = (d1 - d1.mean())/d1.std()\n",
    "# d2 = (d2 - d2.mean())/d2.std()\n",
    "# d3 = (d3 - d3.mean())/d3.std()\n",
    "# d4 = (d4 - d4.mean())/d4.std()\n",
    "# d5 = (d5 - d5.mean())/d5.std()\n",
    "# d6 = (d6 - d6.mean())/d6.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data from the 6 views of Caltech_7 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "X.append(d1.T)\n",
    "X.append(d2.T)\n",
    "X.append(d3.T)\n",
    "X.append(d4.T)\n",
    "X.append(d5.T)\n",
    "X.append(d6.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the above case, there are $6$ views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = len(X) # V is the number of views\n",
    "k = 20 # k is the number of clusters\n",
    "alpha = 10000 # alpha is the regularisation term in the convex optimisation problem\n",
    "m = 100 # here m is the number of anchors for each view\n",
    "n = X[0].shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the anchor graph representation for all the views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=[]\n",
    "for v in range(V):\n",
    "    k_means = KMeans(random_state=25, n_clusters=m, max_iter=1000)\n",
    "    k_means.fit(X[v].T)\n",
    "    A.append(k_means.cluster_centers_.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimension for each of the $A_i$'s is $\\mathbb{R}^{d_i x m}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View 0\n",
      "View 1\n",
      "View 2\n",
      "View 3\n",
      "View 4\n",
      "View 5\n"
     ]
    }
   ],
   "source": [
    "for v in range(V):\n",
    "    print(f'View {v}')\n",
    "    AA = 2 * alpha * np.eye(m) + 2 * A[v].T @ A[v]\n",
    "    AA = (AA + AA.T) / 2\n",
    "    B = X[v]\n",
    "    \n",
    "    d = B.shape[0]\n",
    "    \n",
    "    ff = -2 * (B[:,0].reshape(d,1)).T @ A[v]\n",
    "    q = (ff.T).reshape((m,))\n",
    "    G = -1 * np.eye(m)\n",
    "    h = np.zeros((m, 1)).reshape((m,))\n",
    "    AI = np.ones((m, 1)).reshape((m,))\n",
    "    b = np.array([1.])\n",
    "    \n",
    "    Z = solve_qp(AA, q, G, h, AI, b).reshape(m,1)\n",
    "    for j in range(1, n):\n",
    "        ff = -2 * (B[:,j].reshape(d,1)).T @ A[v]\n",
    "        q = (ff.T).reshape((m,))\n",
    "        \n",
    "        z = solve_qp(AA, q, G, h, AI, b).reshape(m,1)\n",
    "        Z = np.concatenate((Z,z),axis=1)\n",
    "        \n",
    "    D = np.diag(np.divide(1, np.sqrt(np.sum(Z, axis=1))))\n",
    "    Zc = (Z.T @ D).T\n",
    "    \n",
    "    if v == 0:\n",
    "        Sbar = Zc / np.sqrt(V)\n",
    "    else:\n",
    "        Sbar = np.concatenate((Sbar, (1/np.sqrt(V))*Zc), axis=0)\n",
    "        \n",
    "#     if v == 0:\n",
    "#         Sbar = Z / np.sqrt(V)\n",
    "#     else:\n",
    "#         Sbar = np.concatenate((Sbar, (1/np.sqrt(V))*Z), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 2386)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sbar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, _, _ = randomized_svd(Sbar.T, n_components = k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zbar = Zc[0]\n",
    "# for i in range(1, len(Zc)):\n",
    "#     Zbar = np.concatenate((Zbar, Zc[i]),axis=1)\n",
    "# Zbar /= np.sqrt(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zbar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#U, _, _ = randomized_svd(Zbar, n_components = k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2386, 20)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2, 13, ..., 13, 14, 16])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means2 = KMeans(random_state=25, n_clusters=k, max_iter=1000)\n",
    "k_means2.fit(U)\n",
    "k_means2.labels_ + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = k_means2.labels_ + 1\n",
    "# orig = np.load('cal7_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = k_means2.labels_ + 1\n",
    "orig = np.load('cal20_labels.npy').flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hungarian(A):\n",
    "    _, col_ind = linear_sum_assignment(A)\n",
    "    return col_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BestMap(L1, L2):\n",
    "    L1 = L1.flatten(order='F').astype(float)\n",
    "    L2 = L2.flatten(order='F').astype(float)\n",
    "    if L1.size != L2.size:\n",
    "        sys.exit('size(L1) must == size(L2)')\n",
    "    Label1 = np.unique(L1)\n",
    "    nClass1 = Label1.size\n",
    "    Label2 = np.unique(L2)\n",
    "    nClass2 = Label2.size\n",
    "    nClass = max(nClass1, nClass2)\n",
    "\n",
    "    # For Hungarian - Label2 are Workers, Label1 are Tasks.\n",
    "    G = np.zeros([nClass, nClass]).astype(float)\n",
    "    for i in range(0, nClass2):\n",
    "        for j in range(0, nClass1):\n",
    "            G[i, j] = np.sum(np.logical_and(L2 == Label2[i], L1 == Label1[j]))\n",
    "\n",
    "    c = Hungarian(-G)\n",
    "    newL2 = np.zeros(L2.shape)\n",
    "    for i in range(0, nClass2):\n",
    "        newL2[L2 == Label2[i]] = Label1[c[i]]\n",
    "    return newL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI = 0.40657547732761595\n",
      "NMI = 0.6396168585452764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "print(\"ARI = \" + str(adjusted_rand_score(orig, pred)))\n",
    "print(\"NMI = \" + str(normalized_mutual_info_score(orig, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5343671416596815\n"
     ]
    }
   ],
   "source": [
    "pred_ord = BestMap(orig, pred)\n",
    "Missrate = float(np.sum(orig != pred_ord)) / orig.size\n",
    "print(f'Accuracy: {1 - Missrate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[179,   1,   0,   0,   0, 136,   1,   5,   0,   0,   0,   0,  32,\n",
       "         80,   0,   0,   0,   0,   1,   0],\n",
       "       [  0, 180,   0,   0,   0,   0,   0,   0,   1,   0,   1,   0,  18,\n",
       "          0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0, 356, 106,   0,   0,   2,   6,   4,   1, 150,   0,  19,\n",
       "          0,   0,   0, 152,   0,   2,   0],\n",
       "       [  0,   0,   0,   2,   2,   0,   0,  18,   1,   1,   1,   1,   4,\n",
       "          1,   2,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   1,   0,  66,   0,   0,   7,   0,  11,   0,   0,   6,\n",
       "          0,   0,   0,   0,   0,   7,   0],\n",
       "       [  0,   2,   1,   0,   0,   1,   0,  32,   1,   3,   1,   0,   1,\n",
       "          0,   5,   0,   1,   0,   2,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 111,   0,  12,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   1,   0,   0,   0,   0,   1,  45,   0,   0,   0,   0,   4,\n",
       "          0,   0,   0,   0,   0,   1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   7,   1,  52,   0,   1,   0,   4,\n",
       "          0,   2,   0,   0,   0,   0,   0],\n",
       "       [  0,   1,   0,   0,   1,   0,   0,   4,   1,  22,   0,   0,   2,\n",
       "          3,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   3,   1,   0,   5,   0,   0,   0,   4,   3,   4,   0,  32,\n",
       "          0,   2,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   6,   0,   0,   0,   0,   0,   0,   0,  40,   0,\n",
       "          0,   0,   0,   0,   0,   1,   0],\n",
       "       [  0,   0,   0,   0,   2,   0,   0,   3,   4,   4,   1,   0,  45,\n",
       "          0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   4,   2,   1,   0,   0,   0,   2,   4,  19,   0,   0,   2,\n",
       "          0,   0,   0,   0,   0,   1,   0],\n",
       "       [  0,   1,   0,   0,   0,   0,   1,   1,   7,   0,   0,   0,   2,\n",
       "          0,  26,   0,   0,   0,   7,   0],\n",
       "       [  0,   0,   0,   0,   1,   0,   0,  11,   8,   2,   0,   0,  10,\n",
       "          0,   0,  27,   0,   0,   5,   0],\n",
       "       [  0,   1,   0,   0,   0,   0,   0,   0,   8,   1,   4,   0,  14,\n",
       "          0,   0,   0,   0,   0,   9,   0],\n",
       "       [  0,   0,   0,   0,   1,   0,   3,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,  52,   0,   0],\n",
       "       [  0,   0,   0,   1,   0,   0,   0,   0,   2,   1,   0,   0,   6,\n",
       "          0,   1,   0,   0,   0,  28,   0],\n",
       "       [  0,   3,   0,   4,   3,   0,   0,   6,   3,   0,   0,   0,   2,\n",
       "          0,   0,   0,   0,   0,   0,  39]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(orig, pred_ord)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity = 0.5796311818943839\n"
     ]
    }
   ],
   "source": [
    "purity = np.sum(np.max(conf_mat, axis=1))/n\n",
    "print(\"Purity = \" + str(purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
